# Issue #26: Support Multi-source JSON with Failover & Last-one-wins - é–‹ç™ºè¨ˆç”»æ›¸

## æ¦‚è¦

MCPã‚µãƒ¼ãƒãƒ¼ã®è¨­å®šæƒ…å ±ãŒè¤‡æ•°ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ã€æœ€æ–°ç‰ˆãªã©ï¼‰ã«åˆ†æ•£ã—ã¦ã„ã‚‹çŠ¶æ³ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’å—ã‘å…¥ã‚Œå¯èƒ½ã«ã™ã‚‹ã€‚
GASï¼ˆæ›´æ–°æ¤œçŸ¥ï¼‰ã¨Pythonï¼ˆã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ï¼‰ã®ä¸¡æ–¹ã§**ã€Œãƒªã‚¹ãƒˆã®å¾Œæ–¹ã«è¨˜è¿°ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆã™ã‚‹ï¼ˆå¾Œå‹ã¡ï¼‰ã€**ã¨ã„ã†çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã§å®Ÿè£…ã—ã€è¨­å®šã®ä¸€è²«æ€§ã‚’ä¿ã¤ã€‚
è¨­å®šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã¯ **JSONé…åˆ—å½¢å¼** ã‚’æ¡ç”¨ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒ©ãƒ™ãƒ«ï¼‰ã¨IDã‚’ãƒšã‚¢ã§ç®¡ç†ã™ã‚‹ã“ã¨ã§ã€ãƒ­ã‚°ã®å¯èª­æ€§ã¨é‹ç”¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚

---

## é‹ç”¨ã‚¤ãƒ¡ãƒ¼ã‚¸

**ç’°å¢ƒå¤‰æ•° / ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ (`DRIVE_FILE_IDS` / `DRIVE_JSON_FILE_IDS`)**

```json
[
  {"name": "Legacy (A)", "id": "1ABC_legacy_id..."},
  {"name": "Future (C)", "id": "1XYZ_future_id..."},
  {"name": "Latest (B)", "id": "1DEF_latest_id..."}
]
```

| é …ç›® | èª¬æ˜ |
|------|------|
| **ãƒªã‚¹ãƒˆé †åºã®æ„å‘³** | ä¸Šã‹ã‚‰é †ã«ã€Œå„ªå…ˆåº¦ãŒä½ã„ â†’ é«˜ã„ã€ã¨ã™ã‚‹ï¼ˆå¾Œå‹ã¡ï¼‰ |
| **GAS** | ãƒªã‚¹ãƒˆé †ã«èª­ã¿è¾¼ã¿ã€å¾Œç¶šã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ä¸Šæ›¸ããƒãƒ¼ã‚¸ã—ã¦èª¿æŸ»å¯¾è±¡ãƒªã‚¹ãƒˆã‚’ä½œæˆ |
| **Python** | ã¾ãšãƒªã‚¹ãƒˆæœ«å°¾ï¼ˆLatestï¼‰ã®URLã§æ¥ç¶šã‚’è©¦è¡Œã€‚å¤±æ•—ã—ãŸå ´åˆã€ä¸€ã¤æ‰‹å‰ï¼ˆFuture â†’ Legacyï¼‰ã®URLã§ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹ï¼ˆãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ï¼‰ |

---

## Phase 1: Google Apps Script (tools/code.js) ã®æ”¹ä¿®

### 1.1 è¨­å®šãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®å¤‰æ›´ã¨ãƒ‘ãƒ¼ã‚¹å‡¦ç†

**å¤‰æ›´ç‚¹:**
- ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å: `DRIVE_JSON_FILE_ID` â†’ `DRIVE_JSON_FILE_IDS`
- å€¤ã®å½¢å¼: JSONé…åˆ—æ–‡å­—åˆ— `[{"name": "...", "id": "..."}]`

**å®Ÿè£…ã‚¤ãƒ¡ãƒ¼ã‚¸ (`getConfig` å†…):**

```javascript
// ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç©ºé…åˆ—
let driveFileConfigs = [];
const rawValue = props.getProperty('DRIVE_JSON_FILE_IDS');

if (rawValue) {
  try {
    // JSONå½¢å¼ã‚’è©¦è¡Œ
    driveFileConfigs = JSON.parse(rawValue);
  } catch (e) {
    console.warn('JSON parse failed, falling back to comma-separated string');
    // å¾Œæ–¹äº’æ›æ€§: ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—å¯¾å¿œ
    driveFileConfigs = rawValue.split(',').map((id, i) => ({
      name: `Source_${i+1}`,
      id: id.trim()
    }));
  }
}

// é…åˆ—ã§ãªã„å ´åˆï¼ˆå˜ä¸€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç­‰ï¼‰ã®æ­£è¦åŒ–
if (!Array.isArray(driveFileConfigs)) {
  driveFileConfigs = [driveFileConfigs];
}

// configã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«æ ¼ç´
return {
  // ...
  DRIVE_FILE_CONFIGS: driveFileConfigs
};
```

### 1.2 æ›´æ–°æ¤œçŸ¥ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè£…

ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã« `modifiedTime` ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¤‰æ›´ãŒã‚ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ã¨ã™ã‚‹ã€‚

**æ–°è¦é–¢æ•° `fetchModifiedFiles(fileConfigs)`:**

```javascript
/**
 * è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°ã‚’æ¤œçŸ¥ã—ã€å¤‰æ›´ãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å–å¾—
 * @param {Array<{name: string, id: string}>} fileConfigs - ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šã®é…åˆ—
 * @returns {Array<{name: string, id: string, content: object}>} å¤‰æ›´ãŒã‚ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹
 */
function fetchModifiedFiles(fileConfigs) {
  const props = PropertiesService.getScriptProperties();
  const lastModifiedTimes = JSON.parse(props.getProperty('LAST_MODIFIED_TIMES') || '{}');

  const modifiedFiles = [];
  const newModifiedTimes = {};

  for (const config of fileConfigs) {
    try {
      const file = DriveApp.getFileById(config.id);
      const currentModified = file.getLastUpdated().toISOString();
      newModifiedTimes[config.id] = currentModified;

      if (lastModifiedTimes[config.id] !== currentModified) {
        console.log(`ğŸ“ Modified: ${config.name} (${config.id})`);
        const content = JSON.parse(file.getBlob().getDataAsString());
        modifiedFiles.push({ ...config, content });
      } else {
        console.log(`â­ï¸ Unchanged: ${config.name}`);
      }
    } catch (e) {
      console.error(`âŒ Failed to fetch ${config.name}: ${e.message}`);
    }
  }

  props.setProperty('LAST_MODIFIED_TIMES', JSON.stringify(newModifiedTimes));
  return modifiedFiles;
}
```

**å‡¦ç†ãƒ•ãƒ­ãƒ¼:**
1. `LAST_MODIFIED_TIMES` ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ï¼ˆJSONï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰
2. å„ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’å–å¾—ãƒ»æ¯”è¼ƒ
3. å¤‰æ›´ãŒã‚ã‚‹å ´åˆã®ã¿ `DriveApp.getFileById` ã§å†…å®¹ã‚’å–å¾—
4. æ›´æ–°æ—¥æ™‚ã‚’ä¿å­˜
5. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®é…åˆ—ã‚’è¿”å´

### 1.3 ãƒãƒ¼ã‚¸ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¾Œå‹ã¡ï¼‰ã®å®Ÿè£…

**æ–°è¦é–¢æ•° `mergeConfigsLastWins(fileConfigs)`:**

```javascript
/**
 * è¤‡æ•°ã®MCPè¨­å®šã‚’ãƒãƒ¼ã‚¸ã™ã‚‹ï¼ˆå¾Œå‹ã¡ï¼‰
 * @param {Array<{name: string, id: string}>} fileConfigs - ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šã®é…åˆ—
 * @returns {{mcpServers: object}} ãƒãƒ¼ã‚¸ã•ã‚ŒãŸè¨­å®š
 */
function mergeConfigsLastWins(fileConfigs) {
  let mergedServers = {};

  for (const config of fileConfigs) {
    try {
      const file = DriveApp.getFileById(config.id);
      const content = JSON.parse(file.getBlob().getDataAsString());
      const servers = content.mcpServers || {};
      const serverCount = Object.keys(servers).length;

      console.log(`ğŸ“‚ Loaded ${config.name}: ${serverCount} servers`);

      // å¾Œå‹ã¡: ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰æ§‹æ–‡ã§ä¸Šæ›¸ã
      mergedServers = { ...mergedServers, ...servers };
    } catch (e) {
      console.error(`âŒ Failed to load ${config.name}: ${e.message}`);
    }
  }

  console.log(`âœ… Merged total: ${Object.keys(mergedServers).length} servers`);
  return { mcpServers: mergedServers };
}
```

### 1.4 main() é–¢æ•°ã®æ”¹ä¿®

1. `getConfig` ã§è¤‡æ•°è¨­å®šã‚’å–å¾—
2. `mergeConfigsLastWins` ã§ãƒãƒ¼ã‚¸ã•ã‚ŒãŸ `mcpServers` ã‚’å–å¾—
3. ä»¥é™ã®å‡¦ç†ã¯ãƒãƒ¼ã‚¸æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨

```javascript
function main() {
  const CONFIG = getConfig();

  // è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’ãƒãƒ¼ã‚¸
  const fileConfigs = CONFIG.DRIVE_FILE_CONFIGS;
  if (fileConfigs.length === 0) {
    console.error('DRIVE_JSON_FILE_IDS ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚');
    return;
  }

  console.log(`ğŸ“‹ Loading ${fileConfigs.length} config files...`);
  const mcpData = mergeConfigsLastWins(fileConfigs);

  // ä»¥é™ã¯æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ mcpData ã§å‡¦ç†
  // ...
}
```

---

## Phase 2: Python Crawler (tools/crawler/) ã®æ”¹ä¿®

### 2.1 ç’°å¢ƒå¤‰æ•°ã®å¤‰æ›´ã¨ãƒ‘ãƒ¼ã‚¹å‡¦ç†

**å¤‰æ›´ç‚¹:**
- ç’°å¢ƒå¤‰æ•°å: `DRIVE_FILE_IDS`
- å€¤ã®å½¢å¼: JSONé…åˆ—æ–‡å­—åˆ—ï¼ˆæ¨å¥¨ï¼‰ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼ˆäº’æ›ï¼‰

**å®Ÿè£…ã‚¤ãƒ¡ãƒ¼ã‚¸ (`main.py`):**

```python
import json
from typing import TypedDict

class FileConfig(TypedDict):
    name: str
    id: str

def parse_drive_file_ids(env_value: str) -> list[FileConfig]:
    """
    ç’°å¢ƒå¤‰æ•°ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ [{name, id}, ...] ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™

    Args:
        env_value: ç’°å¢ƒå¤‰æ•°ã®å€¤ï¼ˆJSONé…åˆ— or ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰

    Returns:
        FileConfigã®ãƒªã‚¹ãƒˆ
    """
    if not env_value:
        return []

    env_value = env_value.strip()

    # JSONå½¢å¼ã‚’è©¦è¡Œ
    if env_value.startswith('['):
        try:
            configs = json.loads(env_value)
            # é…åˆ—å†…ã®å„è¦ç´ ã‚’æ¤œè¨¼ãƒ»æ­£è¦åŒ–
            result = []
            for i, item in enumerate(configs):
                if isinstance(item, dict):
                    result.append({
                        "name": item.get("name", f"Source_{i+1}"),
                        "id": item.get("id", "")
                    })
                elif isinstance(item, str):
                    result.append({"name": f"Source_{i+1}", "id": item})
            return result
        except json.JSONDecodeError:
            pass

    # å¾Œæ–¹äº’æ›æ€§: ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—
    ids = [id.strip() for id in env_value.split(',') if id.strip()]
    return [{"name": f"Source_{i+1}", "id": id} for i, id in enumerate(ids)]
```

### 2.2 DriveClient ã®è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ

**ãƒ•ã‚¡ã‚¤ãƒ«:** `tools/crawler/src/drive_client.py`

**æ”¹ä¿®å†…å®¹:**
- `fetch_mcp_config` ã¯å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ã¨ã—ã¦ç¶­æŒ
- **æ–°è¦ãƒ¡ã‚½ãƒƒãƒ‰ `fetch_mcp_configs_multi(file_configs)`:**

```python
async def fetch_mcp_configs_multi(
    self, file_configs: list[dict]
) -> dict[str, list[MCPServerConfig]]:
    """
    è¤‡æ•°ã®Driveãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰MCPè¨­å®šã‚’å–å¾—ã—ã€server_idã”ã¨ã«å€™è£œãƒªã‚¹ãƒˆã‚’ä½œæˆ

    Args:
        file_configs: [{"name": "...", "id": "..."}, ...] å½¢å¼ã®ãƒªã‚¹ãƒˆ
                      é †åºã¯å¾Œå‹ã¡å„ªå…ˆï¼ˆãƒªã‚¹ãƒˆæœ«å°¾ãŒæœ€å„ªå…ˆï¼‰

    Returns:
        { server_id: [Config_from_file1, Config_from_file2, ...] }
        å€™è£œãƒªã‚¹ãƒˆã®é †åºã¯ã€å…¥åŠ› file_configs ã®é †åºã¨ä¸€è‡´
    """
    server_candidates: dict[str, list[MCPServerConfig]] = {}

    for config in file_configs:
        name = config.get("name", "Unknown")
        file_id = config.get("id", "")

        if not file_id:
            logger.warning(f"Skipping {name}: no file ID provided")
            continue

        try:
            configs = await self.fetch_mcp_config(file_id)
            logger.info(f"ğŸ“‚ Loaded {name}: {len(configs)} servers")

            for server_config in configs:
                if server_config.id not in server_candidates:
                    server_candidates[server_config.id] = []
                # è¨­å®šã«ã‚½ãƒ¼ã‚¹åã‚’ä»˜ä¸ï¼ˆãƒ­ã‚°ç”¨ï¼‰
                server_config.source_name = name
                server_candidates[server_config.id].append(server_config)

        except Exception as e:
            logger.warning(f"âŒ Failed to fetch {name} ({file_id}): {e}")
            continue

    total_servers = len(server_candidates)
    logger.info(f"âœ… Total unique servers: {total_servers}")
    return server_candidates
```

### 2.3 å„ªå…ˆé †ä½ä»˜ãæ¥ç¶šã¨ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼

**ãƒ•ã‚¡ã‚¤ãƒ«:** `tools/crawler/src/mcp_client.py`

**æ–°è¦ãƒ¡ã‚½ãƒƒãƒ‰ `fetch_tools_with_fallback(server_id, candidates)`:**

```python
async def fetch_tools_with_fallback(
    self,
    server_id: str,
    config_candidates: list[MCPServerConfig],
) -> ServerResult:
    """
    è¨­å®šå€™è£œã‚’é€†é †ï¼ˆå¾Œå‹ã¡å„ªå…ˆï¼‰ã§è©¦è¡Œã—ã€æœ€åˆã«æˆåŠŸã—ãŸçµæœã‚’è¿”ã™

    Args:
        server_id: ã‚µãƒ¼ãƒãƒ¼ID
        config_candidates: è¨­å®šå€™è£œãƒªã‚¹ãƒˆï¼ˆfile_configsé †ã€‚å¾Œæ–¹å„ªå…ˆã§é€†é †å‡¦ç†ï¼‰

    Returns:
        æœ€åˆã«æˆåŠŸã—ãŸæ¥ç¶šã®ServerResultã€ã¾ãŸã¯å…¨å¤±æ•—æ™‚ã¯æœ€å¾Œã®ã‚¨ãƒ©ãƒ¼
    """
    last_result = None

    # é€†é †ã§å‡¦ç†ï¼ˆãƒªã‚¹ãƒˆæœ«å°¾ = æœ€å„ªå…ˆï¼‰
    for config in reversed(config_candidates):
        source_name = getattr(config, 'source_name', 'Unknown')
        logger.debug(f"[{server_id}] Trying {source_name}: {config.url}")

        result = await self.fetch_tools_schema(
            server_id, config.url, config.headers
        )
        last_result = result

        if result.status == "online":
            logger.info(f"âœ… [{server_id}] Connected via {source_name}")
            return result
        else:
            logger.warning(
                f"âš ï¸ [{server_id}] Failed via {source_name}: {result.error_message}"
            )

    # å…¨å€™è£œãŒå¤±æ•—ã—ãŸå ´åˆã€æœ€å¾Œã®çµæœã‚’è¿”ã™
    logger.error(f"âŒ [{server_id}] All {len(config_candidates)} sources failed")
    return last_result
```

### 2.4 main.py ã®çµ±åˆæ”¹ä¿®ï¼ˆä¸¦åˆ—å‡¦ç†ã®ç¶­æŒï¼‰

```python
async def main() -> int:
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šã‚’å–å¾—
    drive_file_ids_str = os.environ.get("DRIVE_FILE_IDS", "")
    file_configs = parse_drive_file_ids(drive_file_ids_str)

    # å¾Œæ–¹äº’æ›æ€§: å˜ä¸€IDç’°å¢ƒå¤‰æ•°ã‚‚ã‚µãƒãƒ¼ãƒˆ
    if not file_configs:
        single_id = os.environ.get("DRIVE_FILE_ID")
        if single_id:
            file_configs = [{"name": "Default", "id": single_id}]

    if not file_configs:
        logger.error("DRIVE_FILE_IDS (or DRIVE_FILE_ID) environment variable is not set")
        return 1

    logger.info(f"ğŸ“‹ Loading {len(file_configs)} config files...")

    # Step 1: å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’å–å¾—ï¼ˆserver_idã”ã¨ã«å€™è£œãƒªã‚¹ãƒˆåŒ–ï¼‰
    drive_client = DriveClient()
    server_candidates = await drive_client.fetch_mcp_configs_multi(file_configs)

    if not server_candidates:
        logger.warning("No MCP servers found in configuration")
        return 0

    # Step 2: ä¸¦åˆ—å‡¦ç†ã§ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ä»˜ãæ¥ç¶š
    logger.info(f"ğŸ” Crawling {len(server_candidates)} servers...")

    mcp_client = MCPClient(timeout=args.timeout, delay=args.delay)
    semaphore = asyncio.Semaphore(args.max_concurrent)

    async def process_server_with_limit(server_id: str, candidates: list) -> ServerResult:
        async with semaphore:
            result = await mcp_client.fetch_tools_with_fallback(server_id, candidates)
            if mcp_client.delay > 0:
                await asyncio.sleep(mcp_client.delay)
            return result

    # ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
    tasks = [
        process_server_with_limit(server_id, candidates)
        for server_id, candidates in server_candidates.items()
    ]

    # ä¸¦åˆ—å®Ÿè¡Œ
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # ä¾‹å¤–å‡¦ç†
    processed_results: list[ServerResult] = []
    server_ids = list(server_candidates.keys())
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            server_id = server_ids[i]
            processed_results.append(
                ServerResult(
                    id=server_id,
                    url="(multiple sources)",
                    status="error",
                    last_checked=datetime.now(timezone.utc).isoformat(),
                    error_message=str(result),
                )
            )
        else:
            processed_results.append(result)

    # ä»¥é™ã¯æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯
    # ...
```

---

## Phase 3: GitHub Actions ã®æ”¹ä¿®

### 3.1 ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ã®æ›´æ–°

**ãƒ•ã‚¡ã‚¤ãƒ«:** `.github/workflows/update_catalog.yml`

```yaml
- name: Run crawler
  env:
    # JSONå½¢å¼ã®IDãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚‹
    DRIVE_FILE_IDS: ${{ secrets.DRIVE_FILE_IDS }}
    # å¾Œæ–¹äº’æ›ç”¨ï¼ˆDRIVE_FILE_IDSãŒæœªè¨­å®šã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    DRIVE_FILE_ID: ${{ secrets.DRIVE_FILE_ID }}
  run: |
    cd tools/crawler
    # ...
```

### 3.2 Secretsè¨­å®šæ‰‹é †

**ãƒªãƒã‚¸ãƒˆãƒªSecretsè¨­å®šï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘æ‰‹é †ï¼‰:**

1. GitHub ãƒªãƒã‚¸ãƒˆãƒªã® **Settings** â†’ **Secrets and variables** â†’ **Actions**
2. æ–°ã—ã„ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆ `DRIVE_FILE_IDS` ã‚’ä½œæˆ
3. å€¤ã¨ã—ã¦ä»¥ä¸‹ã®å½¢å¼ã®JSONæ–‡å­—åˆ—ã‚’è¨­å®š:

```json
[
  {"name": "Legacy", "id": "1ABC_legacy_id..."},
  {"name": "Latest", "id": "1DEF_latest_id..."}
]
```

4. æ—§ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆ `DRIVE_FILE_ID` ã¯å¾Œæ–¹äº’æ›ã®ãŸã‚æ®‹ã—ã¦ãŠãï¼ˆä»»æ„ï¼‰

---

## Phase 4: ãƒ†ã‚¹ãƒˆè¨ˆç”»

### 4.1 GAS ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹

| ã‚±ãƒ¼ã‚¹ | å…¥åŠ› | æœŸå¾…çµæœ |
|--------|------|----------|
| JSONå½¢å¼ | `[{"name":"A","id":"id_a"}]` | æ­£å¸¸ã«ãƒ‘ãƒ¼ã‚¹ã€ãƒ­ã‚°ã« `Loaded A: N servers` |
| è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«é‡è¤‡ãªã— | `[{"name":"A","id":"id_a"},{"name":"B","id":"id_b"}]` | ä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ãŒå«ã¾ã‚Œã‚‹ |
| è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«é‡è¤‡ã‚ã‚Š | `[{"name":"A","id":"id_a"},{"name":"B","id":"id_b"}]` (åŒä¸€server_id) | Bï¼ˆå¾Œæ–¹ï¼‰ã®è¨­å®šãŒå„ªå…ˆã•ã‚Œã‚‹ |
| ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šäº’æ› | `id_a,id_b` | `Source_1`, `Source_2` ã¨ã—ã¦å‡¦ç† |
| å˜ä¸€IDäº’æ› | `id_a` | `Source_1` ã¨ã—ã¦å‡¦ç† |
| ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—å¤±æ•— | `[{"name":"Invalid","id":"bad_id"},{"name":"Valid","id":"good_id"}]` | Validã®ã¿ä½¿ç”¨ã€ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°å‡ºåŠ› |

### 4.2 Python Crawler ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹

| ã‚±ãƒ¼ã‚¹ | å…¥åŠ› | æœŸå¾…çµæœ |
|--------|------|----------|
| JSONå½¢å¼ | `[{"name":"A","id":"id_a"}]` | æ­£å¸¸ã«ãƒ‘ãƒ¼ã‚¹ |
| ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ (å¾Œæ–¹æˆåŠŸ) | `[A(ç„¡åŠ¹URL), B(æœ‰åŠ¹URL)]` | Bï¼ˆæœ«å°¾ï¼‰ã§å³åº§ã«æ¥ç¶šæˆåŠŸ |
| ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ (å‰æ–¹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯) | `[A(æœ‰åŠ¹URL), B(ç„¡åŠ¹URL)]` | Bå¤±æ•— â†’ Aã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ |
| å…¨ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ | `[A(ç„¡åŠ¹), B(ç„¡åŠ¹)]` | offline ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã€å…¨ã‚½ãƒ¼ã‚¹è©¦è¡Œãƒ­ã‚° |
| ä¸¦åˆ—å‡¦ç† | å¤šæ•°ã®ã‚µãƒ¼ãƒãƒ¼ + `--max-concurrent 5` | åŒæ™‚æ¥ç¶šãŒ5ã«åˆ¶é™ã•ã‚Œã‚‹ |
| ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šäº’æ› | `id_a,id_b` | `Source_1`, `Source_2` ã¨ã—ã¦å‡¦ç† |
| å¾Œæ–¹äº’æ› (DRIVE_FILE_ID) | `DRIVE_FILE_ID=id_a` ã®ã¿è¨­å®š | `Default` ã¨ã—ã¦å‡¦ç† |

---

## å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Google Apps Script (tools/code.js)

- [ ] `DRIVE_JSON_FILE_IDS` ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®èª­ã¿è¾¼ã¿å¯¾å¿œï¼ˆJSONé…åˆ—å½¢å¼ï¼‰
- [ ] ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã®å¾Œæ–¹äº’æ›æ€§å¯¾å¿œ
- [ ] `fetchModifiedFiles()` é–¢æ•°ã®å®Ÿè£…
- [ ] `mergeConfigsLastWins()` é–¢æ•°ã®å®Ÿè£…
- [ ] `main()` é–¢æ•°ã®æ”¹ä¿®
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆå€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«å¤±æ•—æ™‚ã®ç¶™ç¶šï¼‰
- [ ] ãƒ­ã‚°å‡ºåŠ›ã«ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆnameï¼‰ã‚’å«ã‚ã‚‹

### Python Crawler (tools/crawler/)

- [ ] `parse_drive_file_ids()` é–¢æ•°ã®å®Ÿè£…ï¼ˆmain.pyï¼‰
- [ ] `fetch_mcp_configs_multi()` ãƒ¡ã‚½ãƒƒãƒ‰ã®å®Ÿè£…ï¼ˆdrive_client.pyï¼‰
- [ ] `MCPServerConfig` ã« `source_name` å±æ€§è¿½åŠ 
- [ ] `fetch_tools_with_fallback()` ãƒ¡ã‚½ãƒƒãƒ‰ã®å®Ÿè£…ï¼ˆmcp_client.pyï¼‰
- [ ] main.py ã®çµ±åˆæ”¹ä¿®ï¼ˆä¸¦åˆ—å‡¦ç†ç¶­æŒï¼‰
- [ ] å¾Œæ–¹äº’æ›æ€§ï¼ˆDRIVE_FILE_ID ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ã®ç¢ºä¿
- [ ] ãƒ­ã‚°å‡ºåŠ›ã«ã‚½ãƒ¼ã‚¹åã‚’å«ã‚ã‚‹

### GitHub Actions

- [ ] `update_catalog.yml` ã®ç’°å¢ƒå¤‰æ•°æ›´æ–°
- [ ] Secretsè¨­å®šæ‰‹é †ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [ ] tools/README.md ã®æ›´æ–°
- [ ] tools/crawler/README.md ã®æ›´æ–°
- [ ] tools/crawler/.env.example ã®æ›´æ–°

---

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³

```
+------------------+      +------------------+      +------------------+
|   Drive File A   |      |   Drive File B   |      |   Drive File C   |
|   "Legacy"       |      |   "Future"       |      |   "Latest"       |
+--------+---------+      +--------+---------+      +--------+---------+
         |                         |                         |
         v                         v                         v
+------------------------------------------------------------------------+
|                         Config Loader                                   |
|   DRIVE_FILE_IDS = [                                                   |
|     {"name": "Legacy", "id": "A"},                                     |
|     {"name": "Future", "id": "B"},                                     |
|     {"name": "Latest", "id": "C"}                                      |
|   ]                                                                    |
+------------------------------------------------------------------------+
         |
         v
+------------------------------------------------------------------------+
|                      Merge Logic (Last-one-wins)                       |
|   åŒä¸€server_idã®å ´åˆ: A â† B â† C (CãŒæœ€çµ‚çš„ã«æ¡ç”¨)                     |
|   ãƒ­ã‚°å‡ºåŠ›: "Loaded Legacy: 10 servers"                                |
|             "Loaded Future: 5 servers"                                  |
|             "Loaded Latest: 8 servers"                                  |
+------------------------------------------------------------------------+
         |
         v
+---------------------------+     +---------------------------+
|   GAS: Merged mcpServers  |     |   Python: server_candidates |
|   (èª¿æŸ»å¯¾è±¡ãƒªã‚¹ãƒˆ)        |     |   { server_id: [A,B,C] }   |
+---------------------------+     +-------------+-------------+
                                                |
                                                v
                                  +---------------------------+
                                  |   Failover Connection     |
                                  |   Try C â†’ B â†’ A          |
                                  |   (é€†é †ã§å„ªå…ˆåº¦é«˜ã„é †)    |
                                  +---------------------------+
```

---

## ä½œæˆæ—¥

2025-12-06

## é–¢é€£Issue

- Issue #26: Support multi-source JSON with consistent "last-one-wins" priority
